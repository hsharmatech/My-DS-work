{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Feature Selection\n",
    "\n",
    "Features play a key role in performance of any machine learning model. Non-important features can impact the model performance. We will learn here automatic feature selection techniques with scikit learn.\n",
    "\n",
    "Feature selection is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested.\n",
    "\n",
    "Three benefits of performing feature selection before modeling your data are:\n",
    "\n",
    "__Reduces Overfitting__: Less redundant data means less opportunity to make decisions based on noise.\n",
    "__Improves Accuracy__: Less misleading data means modeling accuracy improves.\n",
    "__Reduces Training Time__: Less data means that algorithms train faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will use  Pima Indians onset of diabetes dataset for the example. We will implement 4 techniques here for Feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# load data\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "basedataframe = pandas.read_csv(\"diabetes.csv\", names=names)\n",
    "basedataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Removing features with low variance\n",
    "\n",
    "__VarianceThreshold__ is a simple baseline approach to feature selection. It removes all features whose variance doesnâ€™t meet some threshold. By default, it removes all zero-variance features, i.e. features that have the same value in all samples.\n",
    "\n",
    "As an example, suppose that we have a dataset with boolean features, and we want to remove all features that are either one or zero (on or off) in more than 80% of the samples. Boolean features are Bernoulli random variables, and the variance of such variables is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will create a new column in our dataset which has 90% of its values as 0 and 10% as 1. and will check that whether variance Threshold remove it with 80% threshold or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\703177402\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>newcol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    preg  plas  pres  skin  test  mass   pedi  age  class  newcol\n",
       "0      6   148    72    35     0  33.6  0.627   50      1       1\n",
       "1      1    85    66    29     0  26.6  0.351   31      0       0\n",
       "2      8   183    64     0     0  23.3  0.672   32      1       0\n",
       "3      1    89    66    23    94  28.1  0.167   21      0       0\n",
       "4      0   137    40    35   168  43.1  2.288   33      1       0\n",
       "5      5   116    74     0     0  25.6  0.201   30      0       0\n",
       "6      3    78    50    32    88  31.0  0.248   26      1       0\n",
       "7     10   115     0     0     0  35.3  0.134   29      0       0\n",
       "8      2   197    70    45   543  30.5  0.158   53      1       0\n",
       "9      8   125    96     0     0   0.0  0.232   54      1       0\n",
       "10     4   110    92     0     0  37.6  0.191   30      0       1\n",
       "11    10   168    74     0     0  38.0  0.537   34      1       0\n",
       "12    10   139    80     0     0  27.1  1.441   57      0       0\n",
       "13     1   189    60    23   846  30.1  0.398   59      1       0\n",
       "14     5   166    72    19   175  25.8  0.587   51      1       0\n",
       "15     7   100     0     0     0  30.0  0.484   32      1       0\n",
       "16     0   118    84    47   230  45.8  0.551   31      1       0\n",
       "17     7   107    74     0     0  29.6  0.254   31      1       0\n",
       "18     1   103    30    38    83  43.3  0.183   33      0       0\n",
       "19     1   115    70    30    96  34.6  0.529   32      1       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = basedataframe\n",
    "data['newcol'] = 0\n",
    "\n",
    "length = len(data)\n",
    "\n",
    "for i in range (length):\n",
    "    if (i%10 == 0):\n",
    "        data['newcol'][i] = 1\n",
    "\n",
    "data.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6. , 148. ,  72. , ...,  33.6,  50. ,   1. ],\n",
       "       [  1. ,  85. ,  66. , ...,  26.6,  31. ,   0. ],\n",
       "       [  8. , 183. ,  64. , ...,  23.3,  32. ,   1. ],\n",
       "       ...,\n",
       "       [  5. , 121. ,  72. , ...,  26.2,  30. ,   0. ],\n",
       "       [  1. , 126. ,  60. , ...,  30.1,  47. ,   1. ],\n",
       "       [  1. ,  93. ,  70. , ...,  30.4,  23. ,   0. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "sel.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that based on Variance Threshold , last column is eleminated having low variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Univariate feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Univariate feature selection works by selecting those features which shoes strongest relationship with the ouput variable\n",
    "scikit learn have some routines which can help.\n",
    "\n",
    "1. **SelectKBest** removes all but the  highest scoring features\n",
    "2. **SelectPercentile** removes all but a user-specified highest scoring percentage of features\n",
    "3. **GenericUnivariateSelect** allows to perform univariate feature selection with a configurable strategy. This allows to select the best univariate selection strategy with hyper-parameter search estimator.\n",
    "\n",
    "\n",
    "We also need a scoring function that returns univariate scores and p-values (or only scores for SelectKBest and selectPercentile). For regression and classification there are separate scoring functions.\n",
    "\n",
    "1. **For regression**: f_regression, mutual_info_regression\n",
    "2. **For classification**: chi2, f_classif, mutual_info_classif\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In following example we will use selectKBest method with chi square scoring function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "data = basedataframe\n",
    "datavalues = data.values\n",
    "X = datavalues[:,0:8]\n",
    "Y = datavalues[:,8]\n",
    "\n",
    "print (X.shape)\n",
    "print (Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 4)\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=4).fit_transform(X, Y)\n",
    "print (X_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that now we only have those two features which are most important. let us see the features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148.    0.   33.6  50. ]\n",
      " [ 85.    0.   26.6  31. ]\n",
      " [183.    0.   23.3  32. ]\n",
      " [ 89.   94.   28.1  21. ]\n",
      " [137.  168.   43.1  33. ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_new[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "its clear that plass, test, mass and age are selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination (or RFE) recursively remove attributes and build a model on remaining features. RFE use model accuracy and find those featuers or combination of features which contribute the most to predicting the dependent variable.\n",
    "\n",
    "We can use any algorithm to use RFE for featue elimination. In following example we will use Logistic Regression and SVC both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = basedataframe\n",
    "datavalues = data.values\n",
    "X = datavalues[:,0:8]\n",
    "Y = datavalues[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features:  4\n",
      "Selected Features:  [ True  True False False False  True  True False]\n",
      "Feature Ranking:  [1 1 2 4 5 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "#feature extraction using logistic regression\n",
    "\n",
    "Logistic_model = LogisticRegression()\n",
    "Logistic_rfe = RFE(Logistic_model, 4)\n",
    "Logistic_fit = Logistic_rfe.fit(X, Y)\n",
    "\n",
    "print(\"Num Features: \",Logistic_fit.n_features_)\n",
    "print(\"Selected Features: \",Logistic_fit.support_)\n",
    "print(\"Feature Ranking: \",Logistic_fit.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features:  4\n",
      "Selected Features:  [ True  True False False False  True  True False]\n",
      "Feature Ranking:  [1 1 2 4 5 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "#feature extraction using svc \n",
    "\n",
    "svc = SVC(kernel=\"linear\", C=1)\n",
    "svc_rfe = RFE(svc, 4)\n",
    "svc_fit = svc_rfe.fit(X, Y)\n",
    "\n",
    "print(\"Num Features: \",svc_fit.n_features_)\n",
    "print(\"Selected Features: \",svc_fit.support_)\n",
    "print(\"Feature Ranking: \",svc_fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "both model identified same features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal component analysis (PCA) is a dimensionality reduction technique which use Singular Value Decomposition of the data to project it to a lower dimensional space. A property of PCA is that you can choose the number of dimensions or principal component in the transformed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: %s [0.88854663 0.06159078 0.02579012]\n",
      "[[-2.02176587e-03  9.78115765e-02  1.60930503e-02  6.07566861e-02\n",
      "   9.93110844e-01  1.40108085e-02  5.37167919e-04 -3.56474430e-03]\n",
      " [-2.26488861e-02 -9.72210040e-01 -1.41909330e-01  5.78614699e-02\n",
      "   9.46266913e-02 -4.69729766e-02 -8.16804621e-04 -1.40168181e-01]\n",
      " [-2.24649003e-02  1.43428710e-01 -9.22467192e-01 -3.07013055e-01\n",
      "   2.09773019e-02 -1.32444542e-01 -6.39983017e-04 -1.25454310e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# load data\n",
    "data = basedataframe\n",
    "datavalues = data.values\n",
    "X = datavalues[:,0:8]\n",
    "Y = datavalues[:,8]\n",
    "\n",
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\", fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we can see thar first 3 features are able to capture the 96% of variance in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Importance and Select from Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SelectFromModel__ is a meta-transformer that can be used along with any estimator that has a **coef_** or **feature_importances_** attribute after fitting. The features are considered unimportant and removed, if the corresponding coef_ or feature_importances_ values are below the provided threshold parameter.\n",
    "\n",
    "Tree-based estimators (see the __sklearn.tree module__ and forest of trees in the __sklearn.ensemble module__) can be used to compute feature importances, which in turn can be used to discard irrelevant features (when coupled with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11669173 0.21368335 0.09742078 0.08665977 0.07444054 0.14084862\n",
      " 0.12243711 0.1478181 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# load data\n",
    "data = basedataframe\n",
    "datavalues = data.values\n",
    "X = datavalues[:,0:8]\n",
    "Y = datavalues[:,8]\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see there are 4 features which shows importance more than 10% else all other less than 10% . So model should pick those features . only 3 features have importance more than 13%. So if we pass threshold as 13% our model should only add 3 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = SelectFromModel(model, threshold = .13, prefit=True)\n",
    "X_new = target.transform(X)\n",
    "X_new.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
